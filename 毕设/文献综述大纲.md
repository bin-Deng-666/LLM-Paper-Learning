# 1  视觉语言模型的研究现状

介绍视觉语言模型；介绍视觉语言模型基于Transformer的初步工作；给出视觉语言模型的四种分类；给出各种分类的定义；

参考文献：

Attention is all you need

BERT: Pre-training of deep bidirectional transformers for language understanding

VisualBERT: A simple and performant baseline for vision and language

Vilbert: Pretraining task-agnostic vision-linguistic representations for vision-and-language tasks

Llama: Open and efficient foundation language models

## 1.1 Contrastive

介绍contrastive视觉语言模型的定义；介绍Clip、SigLIP、Llip；

参考文献：

Learning transferable visual models from natural language supervision.

Deep residual learning for image recognition.

Sigmoid loss for language image pre-training.

Modeling caption diversity in contrastive vision-language pretraining. 

## 1.2 Masking

介绍masking视觉语言模型的定义；介绍Flava、MaskVLM；

参考文献：

BERT: Pre-training of deep bidirectional transformers for language understanding

Attention is all you need

Masked autoencoders are scalable vision learners.

Self-supervised learning from images with a joint-embedding predictive architecture.

Flava: A foundational language and vision alignment model.

An image is worth 16x16 words: Transformers for image recognition at scale.

D-VAE: Avariational autoencoder for directed acyclic graphs.

Masked vision and language modeling for multi-modal representation learning.

## 1.3 Generative

介绍Generative-based视觉语言模型的定义；介绍CoCa、CM3leon和Chameleon；

参考文献：

Coca: Contrastive captioners are image-text foundation models.

Scaling autoregressive multi-modal models: Pretraining and instruction tuning.

Make-a-scene: Scene-based text-to-image generation with human priors.

OPT: Open pre-trained transformer language models.

Attention is all you need

Mixed-modal early-fusion foundation models.

## 1.4 Pretrained backbones

介绍基于pretrained backbones视觉语言模型的定义；介绍Frozen、MiniGPT；稍微介绍qwen和blip-2；

参考文献：

Multimodal few-shot learning with frozen language models.

High-performance large-scale image recognition without normalization.

Exploring the limits of transfer learning with a unified text-to-text transformer.

Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning.

Flamingo: a visual language model for few-shot learning.

MiniGPT-4: Enhancing vision-language understanding with advanced large language models.

BLIP-2: Bootstrapping language-image pre-training with frozen image encoders and large language models.

Vicuna: An open-source chatbot impressing gpt-4 with 90% chatgpt quality, March 2023.

Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning.

Im2text: Describing images using 1 million captioned photographs.

Laion-400m: Open dataset of CLIP-filtered 400 million image-text pairs.

Qwen-vl: A versatile vision-language model for understanding, localization, text reading, and beyond.

Qwen technical report.

# 2 面向视觉语言模型的对抗攻击方法设计

## 2.1 对抗攻击的早期研究

给出对抗攻击的定义；介绍早期对抗攻击的逐步发展，主要介绍FGSM及其变种；

参考文献：

Intriguing Properties of Neural Networks

Explaining and Harnessing Adversarial Examples

Adversarial Examples in the Physical World

Boosting Adversarial Attacks With Momentum

Improving Transferability of Adversarial Examples With Input Diversity

Evading Defenses to Transferable Adversarial Examples by Translation-Invariant Attacks

Nesterov Accelerated Gradient and Scale Invariance for Adversarial Attacks

Towards Deep Learning Models Resistant to Adversarial Attacks

## 2.2 面向视觉语言模型的对抗攻击策略

介绍随着发展对抗攻击拓展到了视觉语言模型；定义视觉语言模型上对抗攻击并解释它的多样性；介绍基础VLM对抗攻击设计方法；

参考文献：

Abusing Images and Sounds for Indirect Instruction Injection in Multi-Modal LLMs

Are Aligned Neural Networks Adversarially Aligned?

How Robust is Google’s Bard to Adversarial Image Attacks?

On Evaluating Adversarial Robustness of VLMs

On the Adversarial Robustness of Multi-Modal Foundation Models

Visual Adversarial Examples Jailbreak Aligned LLMs

An Image is Worth 1000 Lies

Image Hijacks

Adversarial Robustness for Visual Grounding of MLLMs

# 3 面向视觉语言模型的对抗样本迁移性研究

## 3.1 对抗样本迁移性的基础理论

初步概述对抗攻击并引出迁移性；强调对抗样本迁移性的研究重要性；介绍data augmentation、optimization technique、loss objective、model component四类迁移性攻击；

参考文献：

Delving into transferable adversarial examples and black-box attacks.

Improving transferability of adversarial examples with input diversity

Evading Defenses to Transferable Adversarial Examples by Translation-Invariant Attacks

Boosting adversarial attacks with momentum.

A method for unconstrained convex minimization problem with the rate of convergence o(1/kˆ 2).

Towards transferable targeted attack.

Improving transferability of adversarial patches on face recognition with generative models.

Transferable adversarial perturbations.

Task-generalizable adversarial attack based on perceptual metric.

## 3.2 面向视觉语言模型的对抗样本迁移性探索

介绍从视觉模型发展到视觉语言模型对抗样本迁移的重要性；介绍迁移性的主体：模型和提示；

参考文献：

Transferable multimodal attack on vision-language pre-training models. 

How Robust is Google’s Bard to Adversarial Image Attacks?

On Evaluating Adversarial Robustness of VLMs

An Image is Worth 1000 Lies

Adversarial Robustness for Visual Grounding of MLLMs

Visual Adversarial Examples Jailbreak Aligned LLMs

# 4 现存问题与发展趋势



# 5 结论

