On Evaluating Adversarial Robustness of VLMs

总结：1️⃣方法：图像-图像相似（用扩散模型将目标文本转成图像，然后拉进原图像和生成图像）、基于访问（使用random gradient-free方法计算伪梯度从而实现黑盒攻击 ）2️⃣数据集：使用ImageNet-1K的图像作为原始图像，使用MS-COCO captions作为目标文本。3️⃣衡量标准：用CLIP score衡量图像描述的准确性。4️⃣模型：图像-图像相似攻击中用stable difussion作为将文本转为图像的模型，代理模型包括BLIP、CLIP、BLIP-2、ALBEF；黑盒模型包括UniDiffuser、Img2Prompt、LLaVA、MiniGPT-4；



On the Adversarial Robustness of Multi-Modal Foundation Models

总结：